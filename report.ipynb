{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2dc7da8-6447-43c5-8e1a-f3a8c804d720",
   "metadata": {},
   "source": [
    "# 1.1 - Blog Post: Classification Model for Credit Card Default Analysis 💰 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78f72c53-7d75-4638-9ea6-d49c131d2c30",
   "metadata": {},
   "source": [
    "By: Angelique Clara Hanzell, Andres Zepeda\n",
    "\n",
    "*December 7, 2022*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3df55e1-366e-4fbb-ba75-7f39e01199c3",
   "metadata": {},
   "source": [
    "## Background about the Project\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23f29bc-b9ee-484b-8e74-da9f31e1070e",
   "metadata": {},
   "source": [
    "In 2005, a Taiwanese bank conducted their clients information regarding default payments, demographic factors, credit data, history of payments, and bill statements as seen in [Default of Credit Card Clients Dataset](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset) taken from the UCI's Machine Learning Repository.\n",
    "\n",
    "Our **goal** here is to utilize this data set to use the previous 6 months of repayment history to try to analyze and predict the likelihood whether or not a customer will default in the following month. This is useful for banks to reduce the loss they will have and increase profit. Banks will then give customers credit to accounts that is less likely to default, reducing their risk exposure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9f1107-50d3-44d4-a623-38fcebb4922b",
   "metadata": {},
   "source": [
    "## Components of the Project\n",
    "---\n",
    "Our project was focused on five different areas to reach our goal and objective:\n",
    "1. Data Wrangling \n",
    "2. Exploratory Data Analysis (EDA)\n",
    "3. Different Models\n",
    "4. Interpretation + Feature Importance\n",
    "5. Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "611b7817-6bc1-4087-b2fd-9bc033136ac5",
   "metadata": {},
   "source": [
    "> ### Data Wrangling "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f1c4c85-7944-41a9-a176-aed190dc6965",
   "metadata": {},
   "source": [
    "The [original data set](https://www.kaggle.com/uciml/default-of-credit-card-clients-dataset) has several columns which includes:\n",
    "- `ID`: ID of clients\n",
    "- `LIMIT_BAL`: Amount of given credit (NT Dollars)\n",
    "- `SEX`: Gender \n",
    "- `EDUCATION`: Level of education\n",
    "- `MARRIAGE`: Martial status\n",
    "- `AGE`: Age (Years)\n",
    "- `PAY_#`: Current repayment status \n",
    "- `BILL_AMT#`: Amount of bill statements (NT Dollars)\n",
    "- `PAY_AMT#`: Amount of previous payment (NT Dollars)\n",
    "- `default.payment.next.month`: The target variable which indicates whether or not the customer defaulted the payment for the following month (0 = No, 1 = Yes)\n",
    "\n",
    "We decided to take out some variables from the original data set that will reduce bias, such as `SEX`, which can be discriminatory. We also decided to remove the column `ID` since it is not relevant to our analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5ea79bf-975d-4dc6-aa8e-8a7611898b17",
   "metadata": {},
   "source": [
    "> ### EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76d4a8f-eed2-4aff-ad47-bd6fc7b07af1",
   "metadata": {},
   "source": [
    "Our EDA allowed us to discover some underlying insights that we have not taken into account before. As seen in the visualizations or plots below, for both the amount of bill statements and amount of previous payment there is clearly an uneven distribution, more towards the right."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18d9ea9b-0c9f-40d6-be9b-5b982a862bf0",
   "metadata": {},
   "source": [
    "![bill amount](img/bill_amt.png \"Bill Amount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9caeaf82-6b43-4779-aaf1-a4b6ceba57e4",
   "metadata": {},
   "source": [
    "![pay amount](img/pay_amt.png \"Pay Amount\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1891418f-2ad9-4378-92cf-1be44e59a605",
   "metadata": {},
   "source": [
    "This makes sense when people with a lot of money start asking for large loans such as for starting a business. No outlier removal may be necessary due to the rarity that larger loan amounts could occur and seem to not effect the values to a large degree, and it is unlikely to cause any \"class discrimination\" where class means the economic class of the individual."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "718be262-026e-4641-bfb9-eee908053554",
   "metadata": {},
   "source": [
    "> ### Different Models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eafd7d3-6bdf-4c9e-9ba8-273163803af4",
   "metadata": {},
   "source": [
    "We tried different models for that is suitable for our classification model, starting from [Logistic Regression](https://www.ibm.com/topics/logistic-regression), [K-NN](https://www.ibm.com/topics/knn), [Random Forest](https://www.ibm.com/cloud/learn/random-forest), [CatBoost](https://towardsdatascience.com/catboost-regression-in-6-minutes-3487f3e5b329). At last, we found out that CatBoost worked best and is more trustworthy since it performed the best, as seen below, with an accuracy of ~82% for the optimized version that is achieved through [hyperparameter tuning](https://neptune.ai/blog/hyperparameter-tuning-in-python-complete-guide). We also decided on to use CatBoost as the model is known to outperform other algorithms and the fact that it will treat categorical feature in the best way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dabf881b-af41-46be-a3a3-9fa18b479343",
   "metadata": {},
   "source": [
    "![models](img/models.png \"models\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01bacc84-d9a6-43fc-9d10-0453cb3d9a05",
   "metadata": {},
   "source": [
    "> ### Interpretation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dffb7257-b4e2-49e4-840d-345358d4586c",
   "metadata": {},
   "source": [
    "To see which predictor variables or features actually influence and matters the most for our model, we decided to run [eli5](https://eli5.readthedocs.io/en/latest/blackbox/permutation_importance.html) and [SHAP](https://christophm.github.io/interpretable-ml-book/shap.html) to give us the rank of the from the most important feature to the least important feature. \n",
    "\n",
    "With eli5, we got a table of weight associated with each feature. This value can tell us of how much important a feature is in each of our model. As seen below, when running eli5 on our most accurate model, which is the CatBoost model as mentioned before, we see that the feature `EDUCATION` is the most dominant feature out of all with 24% of importance on the data set. This will infer us an idea how education and whether or not a client will default their credit card is correlated."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a8f3bbf-c5c2-401e-b7d2-15d92adf78c9",
   "metadata": {},
   "source": [
    "![eli5](img/eli_5.png \"eli5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fae2a8fc-12c4-4d7d-97ed-305052b95ad2",
   "metadata": {},
   "source": [
    "While it is suprising and interesting to think that education is the most feature. While one could be surprised by it being the most important by such a large margin, on it's own it makes sense that it matters, as we heuristically know that education is correlated with someone's job and therefore job and ability to repay credit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c24bde18-0529-437b-ac80-178b8292c205",
   "metadata": {},
   "source": [
    "> ### Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad90ba32-5345-4b02-bc5b-709a9b66ceca",
   "metadata": {},
   "source": [
    "After building our model, the most important part will come right now, which is trying our previously built model out on part of the data set that have yet to be seen, or in other words: unseen data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aed7f2a-bc5b-44fc-ade3-8a895d3886fc",
   "metadata": {},
   "source": [
    "![test score](img/test_score.png \"test score\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd96e1e-7a6c-4f3d-a0b4-29d590831039",
   "metadata": {},
   "source": [
    "As we can see and expect, our CatBoost once again has the highest test score, which is aligned with what we found before. With a score of accuracy ~82%, there is certainly some uncertainty regarding the accuracy that we think could be improved, but ~82% do seems like a reasonable model to work with. In other words: for a bank that expects 1000 clients, the error of predicting whether or not the client's will default is around 180 clients."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d9c9bc1-479e-4409-85c3-5a62cfc2c824",
   "metadata": {},
   "source": [
    "## What I Learned & Caveats\n",
    "---\n",
    "From this project, we realized that at the end of the day, there are still a lot of aspects that could be improved to make our overall model stronger, which includes:\n",
    "- We are dealing with a data set where we our main goal is to build a model that can help banks reduce their cost and expenses by not giving out loans to people who are likely to default. The importance of which metrics in this case is critical in order to evaluate our model performance. In our project, we solely focus more on improving the accuracy and precision of the model, but then after carefully understanding the goal of this project, we realized that **improving the recall metrics would have been so much more relevant** with the problem we are trying to solve and specific data set. The recall metrics is the metrics to quantify the number of correct predictions, hence the higher the recall, the fewer the false negatives. Even though our accuracy was as high as ~82%, the recall metrics was relatively much lower. It could be misleading to use this model without trying to improve the recall score.\n",
    "- The CatBoost model that we are dealing with did not necessarily give us the best accuracy as it can be. CatBoost model is in most cases, very expensive and slow to work with, even though they perform the best in the most part. When dealing with the hyperparameter tuning, there are certain areas that we did not put into account, for example doing more hyperparameter tuning with grid search due to it taking a very long time when we tried more combinations of parameters. On the other hand, the small possible combinations of hyperparameter could be misleading.\n",
    "- We could have done more rigorous feature selection and engineering (the optional part we didn't do). Aside from the second point of caveat (where we only tried a small portion of the possible combinations of hyperparameter), there could also be a big likelihood that our final metrics is not performing the best that it could because we did not do more feature selection (e.g. forward selection) and feature engineering. Feature selection in this case could help us deal with smaller amount of features - which will make the hyperparameter optimization a lot faster to work with and hence improve our CatBoost model overall, which will lead to the improvement of our metrics. There are certainly possibilities that some of the features are not as important, as seen on the eli5 table previously, that some features contributed very little importance, and feature selection would be ideal to avoid this. Manipulating (addition, deletion, combination, mutation) our features through feature engineering could also be another way where we could improve our metrics.\n",
    "\n",
    "Overall, we think that we did a great job in the project. Machine learning is certainly a vast field, there will be a lot of different ways one could tackle a problem - and a lot of improvement could be made as time goes on!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "159c2bb7-63af-499f-a405-e5a085548026",
   "metadata": {},
   "source": [
    "# 1.2 - Effective Communication Technique 🤝"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88ac2a07-721a-4d8e-9e30-0cd1950e96eb",
   "metadata": {},
   "source": [
    "As this is our first time in incorporating our project in a blog post, we are particularly happy with our interpretation and results part, since we know that for most people - the results are usually what matters and overall we are satisified with it. We used one of the communication technique, where \"Interesting to you != useful to the reader (aka it's not about you)\". \n",
    "\n",
    "There are certainly some things that is interesting for me but not useful for the reader (such as the hyperparameter tuning part - it will be harder to follow along for someone especially when they do not have a background in machine learning), we decided to leave that part and elaborate more on how it is pretty interesting how education is considered the most important feature out of all the other features. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31dc5a19-9f4c-40e9-97a2-b0ef0b8789ff",
   "metadata": {},
   "source": [
    "# 2 - Takeaway from the Course 🌱"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07d89f75-b5e3-4785-90de-d57bd689d62a",
   "metadata": {},
   "source": [
    "I am going to be honest, when I first took this course, I did not know what I was expecting since I did not have any experience in machine learning before, aside from the basic algorithms, such as K-NN. \n",
    "\n",
    "After the past 4 months, this course is absolutely amazing, and I can say that this is the most enjoyable course I have taken throughout my degree at UBC. I enjoyed every single part of it, lectures were engaging and homeworks were really fun to play around with. It was really fun seeing how data wrangling could be the most important part before moving on to building the model itself. I believe that having mastery in machine learning would require a lot of education, practice, and also passion. \n",
    "\n",
    "Thanks to this course, I have gained a lot of understanding on how machine learning works along with the reasoning behind it - and as a future data scientist (will be doing my very first co-op in this role in the upcoming January), I am very excited to use this course in a more practical capacity - from data wrangling, model, writing a report on projects (which is very important to elaborate our model to non-technical people), up until deployment. The field of machine learning is vast, and it is like solving a puzzle for me.\n",
    "\n",
    "Thank you a lot for professor Varada and also all the teaching assitants who have put a lot effort in delivering this course the best way that it could be! "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
